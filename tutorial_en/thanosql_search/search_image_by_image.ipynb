{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e43f86f8-a77c-4f93-a194-5c8dbd954871",
   "metadata": {},
   "source": [
    "# __Search image by image__\n",
    "\n",
    "**Understanding image digitization techniques**\n",
    "---\n",
    "ðŸ‘‰ Images are high-dimensional data (height x width x channel (RGB) x color intensity), which means nothing if the information of each pixel is randomly generated. In other words, each pixel can only be recognized as an image if it has a specific pattern associated with the surrounding pixel. This means that an image can be represented on a lower-dimensional characteristic vector than it really is. Recently, studies using artificial intelligence to numericalize and express each image in a low-dimensional space according to the similarity of the meaning of each image have been conducted in various ways, and these have been used in various names such as image digitization, vectorization, and embedding.\n",
    "\n",
    "**In this tutorial**\n",
    "---\n",
    "ðŸ‘‰ This tutorial will use the MNIST handwriting dataset. Each image is a fixed size (28x28 = 784 pixels) with a value between 0-1 and provides a number from 0-9 written by many people with the correct answer. It consists of 1,000 learning datasets and 200 testing datasets.\n",
    "\n",
    "Let's create a model that uses ThanoSQL to enter handwriting data and search for images similar to the input image within the DB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd38a02-06a5-405b-82e0-b074a3dbf589",
   "metadata": {},
   "source": [
    "## __0. Check dataset__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d1d13a",
   "metadata": {},
   "source": [
    "To use the query syntax of ThanoSQL, you must create an API token and run the query below, as mentioned in the [ThanoSQL Workspace](https://docs.thanosql.ai/quick_start/how_to_use_ThanoSQL/#5-thanosql)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac3be35-fc75-432f-8946-2cb57fd56bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext thanosql\n",
    "%thanosql API_TOKEN=<Issued_API_TOKEN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63661751-7e32-48f7-84fa-1dd205cc5d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "COPY mnist_train \n",
    "OPTIONS(overwrite = True)\n",
    "FROM \"tutorial_data/mnist_data/mnist_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65244d4-97bc-4464-aa8c-2d12a1f59435",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "COPY mnist_test \n",
    "OPTIONS(overwrite = True)\n",
    "FROM \"tutorial_data/mnist_data/mnist_test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6845948",
   "metadata": {},
   "source": [
    "__OPTIONS__ : \n",
    "\n",
    "When __overwrite is true__, the user can create a data table with the same name as the previously created data table.  \n",
    "On the other hand, when __overwrite is False__, the user cannot create a data table with the same name as the previously created data table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542deaf1-606f-49ea-9b6d-5721050ff2bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## __1. Check dataset__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4173ef2-b099-4f54-8b20-5ecae6fab51c",
   "metadata": {},
   "source": [
    "Use the mnist_train table stored in the ThanoSQL DB to create a handwriting classification model. The mnist_train table is a table containing the path, file name, and label information where MNIST image files are stored. Run the query statement below and check the contents of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242430e8-09f5-4f2c-9133-21015fc0acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "SELECT * \n",
    "FROM mnist_train \n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648a0843",
   "metadata": {},
   "source": [
    "The mnist_train table contains the following information: The \"6782.jpg\" image file is a handwritten image with the number 5.\n",
    "\n",
    "- img_path: Image Path\n",
    "- filename: file name\n",
    "- label : image label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f3acf-f218-4d51-b671-7651632290ec",
   "metadata": {},
   "source": [
    "## __2. Creating an Image Numerical Model__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaad6bd-ae89-4b32-9bdf-3cbe9c2e685e",
   "metadata": {},
   "source": [
    "Create an image quantification model using the mnist_train table from the previous step. Execute the query syntax below to create a model named my_image_search_model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5d133a",
   "metadata": {},
   "source": [
    "(Estimated time required for query execution: 1 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3630f8f7-8229-49f5-ae32-51011e1e37c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "BUILD MODEL my_image_search_model\n",
    "USING SimCLR\n",
    "OPTIONS (\n",
    "    image_col=\"img_path\",\n",
    "    max_epochs=5,\n",
    "    overwrite=True\n",
    "    )\n",
    "AS \n",
    "SELECT * \n",
    "FROM mnist_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e173c0d",
   "metadata": {},
   "source": [
    "# __Query Details__ \n",
    "- Create and train a model called my_image_search_model using the query syntax \"__BUILD MODEL__\".\n",
    "- The \"__USING__\" query syntax specifies the use of the SimCLR model as the base model.\n",
    "- Specify the options to use for model creation via the query syntax \"__OPTIONS__\".  \n",
    "    -  \"image_col\" : Column containing image path in data table (Default: \"image_path\")    \n",
    "    -  \"max_epochs\" : Number of dataset learnings to generate image quantization models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4b8b03",
   "metadata": {},
   "source": [
    "Use the query syntax below to view the results of the image quantification. Embedding images `mnist_test` using the query syntax '__CONVERTUSING__' `my_image_search_model`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abffc4b-aec9-444a-9546-dce181190f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "CONVERT USING my_image_search_model\n",
    "OPTIONS (\n",
    "    table_name= \"mnist_test\",\n",
    "    image_col=\"img_path\"\n",
    "    )\n",
    "AS \n",
    "SELECT * \n",
    "FROM mnist_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb189a3",
   "metadata": {},
   "source": [
    "__Query Details__ \n",
    "- The query syntax \"__CONVERT USING__\" uses `my_image_search_model` as an algorithm for image quantification.   \n",
    "- Define the variables required for image quantification with the query syntax \"__OPTIONS__\". \n",
    "    - \"table_name\" : Defines the table name to be stored in the ThanoSQL DB.\n",
    "    - \"image_col\" : Defines the column name containing the image file path in the data table. (DEFAULT: \"image_path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1705aa14",
   "metadata": {},
   "source": [
    "Create a new column named `my_image_search_model_simclr` in the table `mnist_test` and save the quantization results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c16f866-b5b4-4540-a848-30d0cd459165",
   "metadata": {},
   "source": [
    "## __3. Search for similar images using image quantization models__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3692372-1572-4547-931d-4d3a861eb103",
   "metadata": {},
   "source": [
    "This step uses the my_image_search_model image quantization model and the test table to search for images similar to the \"923.jpg\" image file (handwriting 8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e0de08-b6a7-4087-8691-230243aab016",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "SEARCH IMAGE images='tutorial_data/mnist_data/test/923.jpg' \n",
    "USING my_image_search_model \n",
    "AS\n",
    "SELECT * \n",
    "FROM mnist_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9871fe36",
   "metadata": {},
   "source": [
    "__Query Details__  \n",
    "\n",
    "- The query syntax \"___SEARCH IMAGE images=__\" defines the image file you want to search for.  <br>\n",
    "- \"__USING__\" defines the model used for image quantification.<br>\n",
    "- The \"__AS__\" query syntax defines the embedding table to use for searches. Use table `mnist_embds`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12953f08",
   "metadata": {},
   "source": [
    "Run the following query to output the \"__SEARCH__\" result using the \"__PRINT__\" query syntax in ThanoSQL to output the top four most similar. We've only done a little bit of learning, but you can see that it's outputting an image similar to 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77af4961-def3-4884-bea2-b8e917d9ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "PRINT IMAGE \n",
    "AS (\n",
    "    SELECT image_path, my_image_search_model_simclr_similarity1 \n",
    "    FROM (\n",
    "        SEARCH IMAGE images='tutorial_data/mnist_data/test/923.jpg' \n",
    "        USING my_image_search_model \n",
    "        AS \n",
    "        SELECT * \n",
    "        FROM mnist_test\n",
    "        )\n",
    "    ORDER BY my_image_search_model_simclr_similarity1 DESC \n",
    "    LIMIT 4\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517479e8",
   "metadata": {},
   "source": [
    "__Notes for reference__ \n",
    "\n",
    "The basic learning options of the image similarity search algorithm are learned to recognize the image as the same regardless of the image's left-right inversion, color change, etc. This is because a dog's picture should be recognized as a dog even if it is flipped or changed in color. If color changes are important, such as clothing images, or if vertical and horizontal twists are important, such as numbers, the options should be changed when learning. This tutorial shows the characteristics of these image similarity searches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
