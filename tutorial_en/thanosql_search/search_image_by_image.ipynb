{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e43f86f8-a77c-4f93-a194-5c8dbd954871",
   "metadata": {},
   "source": [
    "# __Search image by image__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01de980",
   "metadata": {},
   "source": [
    "## Preface\n",
    "\n",
    "- Tutorial Difficulty : â˜…â˜†â˜†â˜†â˜†\n",
    "- 7 min read\n",
    "- Languages : [SQL](https://en.wikipedia.org/wiki/SQL) (100%)\n",
    "- File location : tutorial_en/thanosql_search/search_image_by_image.ipynb\n",
    "- References : [MNIST DataSet](http://yann.lecun.com/exdb/mnist/), [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/abs/2002.05709)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e19c02",
   "metadata": {},
   "source": [
    "## Introduction to the tutorial\n",
    "\n",
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Understanding image digitization techniques</h4>\n",
    "    <p>Images are high-dimensional data (height x width x channel [RGB] x color intensity), which is meaningless if the information for each pixel is randomly generated. In other words, an image can only be recognized as an image if each pixel has a specific pattern associated with the surrounding pixels. With this information, it can be inferred that an image can be represented on a low-dimensional feature vector than what the image is comprised of. Recently, studies using artificial intelligence to numericalize and express each image in a low-dimensional space based on the similarity of each image have been conducted in the form of image digitization, vectorization, and embedding.</p>\n",
    "</div>\n",
    "\n",
    "There are several ways to define the similarity of an image. It could be that the colors are similar, the objects in the image are similar, or the context of the image may be similar, such as a value of a handwritten number. Although it is difficult to give an exact definition of a similar image, artificial intelligence learns and quantifies these general characteristics.\n",
    "\n",
    "ThanoSQL uses the [Self-Supervised Learning Model](https://en.wikipedia.org/wiki/Self-supervised_learning) to input images into the database (DB) and retrieve similar images from it. When you upload your images to ThanoSQL's DB, similar images are placed closer while non-similar images are placed further away by an artificial intelligence algorithm. You can derive a general definition of an image from a dataset with no label, fine-tune it to an image with a small amount of target values, and use it for classification or regression tasks.\n",
    "\n",
    "In addition, ThanoSQL uses artificial intelligence algorithms to quantify datasets. The vectorized data is stored as a DB column in the image table and is used to calculate the similarity(distance) to search for similar images.\n",
    "\n",
    "__The following are use case examples of ThanoSQL's similar image search algorithm.__\n",
    "\n",
    "- Inputting your favorite image and having similar artworks within the DB searched and recommended back to you.\n",
    "- Finding similar images within an album containing thousands of photos.\n",
    "- Creating your own search engine or artificial intelligence model by storing the numerical value of the image in ThanoSQL's DB, and using the ThanoSQL Auto-ML regression/classification prediction model.\n",
    " \n",
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">In this tutorial</h4>\n",
    "    <p>ðŸ‘‰ This tutorial will use the <mark style=\"background-color:#FFD79C\">MNIST handwriting dataset</mark>. Each image is a fixed size(28x28 = 784 pixels) with a decimal value between 0 to 1, consisting of a number from 0 to 9 written by different people, and is correctly labeled. The MNIST handwriting dataset consists of 1,000 train images and 200 test images.</p>\n",
    "</div>\n",
    "    \n",
    "Try creating a model that uses ThanoSQL to input handwriting data and retrieves similar images in the DB.\n",
    "\n",
    "[![IMAGE](https://docs.thanosql.ai/img/thanosql_search/search_image_by_image/simclr_img7.png \"MNIST data\") ](https://docs.thanosql.ai/img/thanosql_search/search_image_by_image/simclr_img7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd38a02-06a5-405b-82e0-b074a3dbf589",
   "metadata": {},
   "source": [
    "## __0. Prepare Dataset__\n",
    "\n",
    "To use the query syntax of ThanoSQL, you must create an API token and run the query below, as mentioned in the [ThanoSQL Workspace](https://docs.thanosql.ai/en/getting_started/how_to_use_ThanoSQL/#5-thanosql-workspace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac3be35-fc75-432f-8946-2cb57fd56bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext thanosql\n",
    "%thanosql API_TOKEN=<Issued_API_TOKEN>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073a6182",
   "metadata": {},
   "source": [
    "### __Prepare Dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b80b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "GET THANOSQL DATASET mnist_data\n",
    "OPTIONS (overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec2d024",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>\"<strong>GET THANOSQL DATASET</strong>\" Use this query to save the desired dataset to your workspace environment. </li>\n",
    "        <li>\"<strong>OPTIONS</strong>\" Use this statement to specify the options to use for the <strong>GET THANOSQL DATASET</strong> query.\n",
    "        <ul>\n",
    "            <li>\"overwrite\" : Overwrite if a dataset with the same name exists. If set as True, the existing dataset is replaced with the new dataset (True|False, DEFAULT : False) </li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63661751-7e32-48f7-84fa-1dd205cc5d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "COPY mnist_train \n",
    "OPTIONS (overwrite=True)\n",
    "FROM \"thanosql-dataset/mnist_data/mnist_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65244d4-97bc-4464-aa8c-2d12a1f59435",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "COPY mnist_test \n",
    "OPTIONS (overwrite=True)\n",
    "FROM \"thanosql-dataset/mnist_data/mnist_test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6845948",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>Use the \"<strong>COPY</strong>\" query statement to specify the dataset to be copied into the DB. </li>\n",
    "        <li>\"<strong>OPTIONS</strong>\" specifies the options to use for the <strong>COPY</strong> query statement.\n",
    "        <ul>\n",
    "            <li>\"overwrite\" : Overwrite if a dataset with the same name exists in the DB. If True, the existing dataset is overwritten with the new dataset (True|False, DEFAULT: False) </li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542deaf1-606f-49ea-9b6d-5721050ff2bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## __1. Checking the Dataset__\n",
    "\n",
    "To create a handwriting classification model, use the <mark style=\"background-color:#FFEC92\">mnist_train</mark> table stored in the ThanoSQL [DB](https://en.wikipedia.org/wiki/Database). The <mark style=\"background-color:#FFEC92\">mnist_train</mark> table contains the file name, label information, and path that contains the <mark style=\"background-color:#FFD79C\">MNIST</mark> image files. Run the query below and check the contents of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242430e8-09f5-4f2c-9133-21015fc0acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "SELECT * \n",
    "FROM mnist_train \n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648a0843",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Understanding the Data Table</h4>\n",
    "    <p>The <mark style=\"background-color:#FFEC92\">mnist_train</mark> table contains the following information: The \"6782.jpg\" image file is a handwritten image with the number 5.</p>\n",
    "    <ul>\n",
    "        <li><mark style=\"background-color:#D7D0FF\">image_path</mark>: image path</li>\n",
    "        <li><mark style=\"background-color:#D7D0FF\">filename</mark>: file name</li>\n",
    "        <li><mark style=\"background-color:#D7D0FF\">label</mark>: image label</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f3acf-f218-4d51-b671-7651632290ec",
   "metadata": {},
   "source": [
    "## __2. Creating an Image Numerical Model__\n",
    "\n",
    "Create an image quantification model using the <mark style=\"background-color:#FFEC92\">mnist_train</mark> table referenced in the previous step. Execute the query below to create a model named <mark style=\"background-color:#E9D7FD\">my_image_search_model</mark>.  \n",
    "(Estimated time required for query execution: 1 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3630f8f7-8229-49f5-ae32-51011e1e37c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "BUILD MODEL my_image_search_model\n",
    "USING SimCLR\n",
    "OPTIONS (\n",
    "    image_col=\"image_path\",\n",
    "    max_epochs=1,\n",
    "    overwrite=True\n",
    "    )\n",
    "AS \n",
    "SELECT * \n",
    "FROM mnist_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e173c0d",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>Create and train a model called <mark style=\"background-color:#E9D7FD\">mnist_model</mark> using the \"<strong>BUILD MODEL</strong>\" query statement.</li>\n",
    "        <li>The \"<strong>USING</strong>\" query statement specifies that the <mark style=\"background-color:#E9D7FD\">SimCLR</mark> model should be used as the base model.</li>\n",
    "        <li>\"<strong>OPTIONS</strong>\" specifies the options for the query used to create a model.\n",
    "        <ul>\n",
    "            <li>\"image_col\" : Column containing the path of the image in the data table (Default: \"<mark style=\"background-color:#D7D0FF\">image_path</mark>\")</li>\n",
    "            <li>\"max_epochs\" : Number of dataset training to be done to generate image quantization models</li>\n",
    "            <li>\"overwrite\" : Overwrite if a model with the same name exists. If true, the existing model is replaced with the new model (True|False, DEFAULT: False) </li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4b8b03",
   "metadata": {},
   "source": [
    "Run the following \"__CONVERT USING__\" query statement to digitize the `mnist_test` images. The quantized results are stored in a column named <mark style=\"background-color:#D7D0FF\">my_image_search_model_simclr</mark> in the table, `mnist_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abffc4b-aec9-444a-9546-dce181190f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "CONVERT USING my_image_search_model\n",
    "OPTIONS (\n",
    "    table_name= \"mnist_test\",\n",
    "    image_col=\"image_path\"\n",
    "    )\n",
    "AS \n",
    "SELECT * \n",
    "FROM mnist_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb189a3",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>The \"<strong>CONVERT USING</strong>\" query statement uses <code>my_image_search_model</code> as an algorithm for image quantification.   </li>\n",
    "        <li>The \"<strong>OPTIONS</strong>\" query statement defines the options required for image quantification.\n",
    "        <ul>\n",
    "            <li>\"table_name\" : Defines the table name to be stored in the ThanoSQL DB. </li>\n",
    "            <li>\"image_col\" : Defines the column containing the path of the image in the data table (default: \"image_path\")</li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c16f866-b5b4-4540-a848-30d0cd459165",
   "metadata": {},
   "source": [
    "## __3. Search for Similar Images Using Image Quantization Models__\n",
    "\n",
    "This step uses the <mark style=\"background-color:#E9D7FD\">my_image_search_model</mark> image quantization model and the test table to search for images similar to the \"923.jpg\" image file (handwritten 8).\n",
    "\n",
    "<a href=\"https://docs.thanosql.ai/img/thanosql_search/search_image_by_image/simclr_img8.png\">\n",
    "    <img alt=\"IMAGE\" src=\"https://docs.thanosql.ai/img/thanosql_search/search_image_by_image/simclr_img8.png\" style=\"width:100px\">\n",
    "</a>\n",
    "\n",
    "<p style=\"text-align:center\">923.jpg Image File </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e0de08-b6a7-4087-8691-230243aab016",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "SEARCH IMAGE images='thanosql-dataset/mnist_data/test/923.jpg' \n",
    "USING my_image_search_model \n",
    "AS\n",
    "SELECT * \n",
    "FROM mnist_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9871fe36",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>\"<strong>SEARCH IMAGE [images|audio|videos]</strong>\" query statement defines the image|audio|video file you want to use for your search.  <br></li>\n",
    "        <li>\"<strong>USING</strong>\" defines the model used for image quantification.<br></li>\n",
    "        <li>The \"<strong>AS</strong>\" query statement defines the embedding table to use for searches. The <code>mnist_embds</code> table is used. </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12953f08",
   "metadata": {},
   "source": [
    "Run the following query to output the \"__SEARCH__\" result using the \"__PRINT__\" query statement in ThanoSQL to output the top four most similar images. We've only done a minimal amount of learning, but you can see that it's outputting images similar to 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77af4961-def3-4884-bea2-b8e917d9ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "PRINT IMAGE \n",
    "AS (\n",
    "    SELECT image_path, my_image_search_model_simclr_similarity1 \n",
    "    FROM (\n",
    "        SEARCH IMAGE images='thanosql-dataset/mnist_data/test/923.jpg' \n",
    "        USING my_image_search_model \n",
    "        AS \n",
    "        SELECT * \n",
    "        FROM mnist_test\n",
    "        )\n",
    "    ORDER BY my_image_search_model_simclr_similarity1 DESC \n",
    "    LIMIT 4\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517479e8",
   "metadata": {},
   "source": [
    "<div class=\"admonition danger\">\n",
    "    <h4 class=\"admonition-title\">Note</h4>\n",
    "    <p>The basic learning options of the image similarity search algorithm are learned to recognize the image as the same regardless of the image's left-right inversion, color differences, and etc. This is because a dog's picture should be recognized as a dog even if it is flipped or changed in color. If color changes are important, such as clothing images, or if vertical and horizontal twists are important, such as numbers, the options should be changed when learning.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5389cb4a",
   "metadata": {},
   "source": [
    "## __4. In Conclusion__\n",
    "\n",
    "In this tutorial, we used the `MNIST` handwriting dataset to perform image quantification and similar image search based on quantification results. We aimed to explain the operation rather than focusing on the accuracy of image similarity. The image quantification model's accuracy can be improved by adding precise tuning and small amounts of labels to each image dataset during learning. You can create your own image quantification model to add search capabilities to various types of unstructured datasets and deploy your own model using Auto-ML techniques.\n",
    "<br>\n",
    "The next step is to explore the various \"__OPTIONS__\" and learning methods of image quantification models. If you want to learn more on how to build your own accurate image conversion model, go ahead with the following tutorials.\n",
    "\n",
    "- [How to Upload to ThanoSQL DB](https://docs.thanosql.ai/en/how-to_guides/ThanoSQL_connecting/data_upload/)\n",
    "- [Creating an Intermediate Similar Image Search Model]\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "    <h4 class=\"admonition-title\">Inquiries about deploying a model for your own service</h4>\n",
    "    <p>If you have any difficulties creating your own model using ThanoSQL or applying it to your services, please feel free to contact us belowðŸ˜Š</p>\n",
    "    <p>For inquiries about building a image similarity search model: contact@smartmind.team</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
