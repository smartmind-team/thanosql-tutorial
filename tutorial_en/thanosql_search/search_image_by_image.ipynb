{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e43f86f8-a77c-4f93-a194-5c8dbd954871",
   "metadata": {},
   "source": [
    "# __Search image by image__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01de980",
   "metadata": {},
   "source": [
    "## Preface\n",
    "\n",
    "- Tutorial Difficulty : â˜…â˜†â˜†â˜†â˜†\n",
    "- 7 min read\n",
    "- Languages : [SQL](https://en.wikipedia.org/wiki/SQL) (100%)\n",
    "- File location : tutorial_en/thanosql_search/search_image_by_image.ipynb\n",
    "- References : [MNIST DataSet](http://yann.lecun.com/exdb/mnist/), [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/abs/2002.05709)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e19c02",
   "metadata": {},
   "source": [
    "## Introduction to the tutorial\n",
    "\n",
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Understanding image digitization techniques</h4>\n",
    "    <p>Images are high-dimensional data (height x width x channel [RGB] x color intensity), which means nothing if the information for each pixel is randomly generated. In other words, each pixel can only be recognized as an image if it has a specific pattern associated with the surrounding pixel. This means that an image can be represented on a lower-dimensional characteristic vector than it really is. Recently, studies using artificial intelligence to numericalize and express each image in a low-dimensional space according to the similarity of the meaning of each image have been conducted in various ways, and these have been used in various names such as image digitization, vectorization, and embedding.</p>\n",
    "</div>\n",
    "\n",
    "There are several ways to define the similarity of an image. It could be that the colors are similar, the objects in the image are similar, or they have the same meaning, such as handwriting. Although it is difficult to give an exact definition of a similar image, artificial intelligence learns and quantifies the general characteristics of an image.\n",
    "\n",
    "ThanoSQL uses [Self-Supervised Learning Model](https://en.wikipedia.org/wiki/Self-supervised_learning) to input images and retrieve similar images from DB . When users upload their images to ThanoSQL's DB, they learn by themselves by placing similar images close and other images far away through an artificial intelligence algorithm. You can learn a general representation of an image from a dataset with no correct answer, fine-tune it to an image with a small amount of target values, and use it for classification or regression tasks.\n",
    "\n",
    "In addition, ThanoSQL uses artificial intelligence algorithms to quantify datasets. The digitized data is stored in the DB column and used to search for similar images by calculating the similarity(distance) between images.\n",
    "\n",
    "__The following is an example of the ThanoSQL similar image search algorithm.__\n",
    "\n",
    "- When a user's favorite image is input, it searches for works of art with a similar feeling among the works of art stored in the DB and recommends them to the user.\n",
    "- Find similar images in an album of thousands of photos.\n",
    "- You can create your own search engine or artificial intelligence model by storing the numerical value of the image in ThanoSQL's DB, and using the ThanoSQL Auto-ML regression/classification prediction model.\n",
    " \n",
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">In this tutorial</h4>\n",
    "    <p>ðŸ‘‰ This tutorial will use <mark style=\"background-color:#FFD79C\">MNIST handwriting dataset</mark>. Each image is a fixed size(28x28 = 784 pixels) with a value between 0 and 1 and provides a number from 0 to 9 written by many people with the correct answer. It consists of 1,000 learning datasets and 200 testing datasets.</p>\n",
    "</div>\n",
    "    \n",
    "Try creating a model that uses ThanoSQL to input handwriting data and retrieves images similar to the input image in the DB.\n",
    "\n",
    "[![IMAGE](https://docs.thanosql.ai/img/thanosql_search/search_image_by_image/simclr_img7.png \"MNIST data\") ](https://docs.thanosql.ai/img/thanosql_search/search_image_by_image/simclr_img7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd38a02-06a5-405b-82e0-b074a3dbf589",
   "metadata": {},
   "source": [
    "## __0. Prepare Dataset__\n",
    "\n",
    "To use the query syntax of ThanoSQL, you must create an API token and run the query below, as mentioned in the [ThanoSQL Workspace](https://docs.thanosql.ai/en/getting_started/how_to_use_ThanoSQL/#5-thanosql-workspace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac3be35-fc75-432f-8946-2cb57fd56bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext thanosql\n",
    "%thanosql API_TOKEN=<Issued_API_TOKEN>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073a6182",
   "metadata": {},
   "source": [
    "### __Prepare Dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b80b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "GET THANOSQL DATASET mnist_data\n",
    "OPTIONS (overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec2d024",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>\"<strong>GET THANOSQL DATASET</strong>\" Use the query syntax to save the desired dataset to the workspace. </li>\n",
    "        <li>\"<strong>OPTIONS</strong>\"Specifies the option to use for <strong>GET THANOSQL DATASET</strong> via query syntax.\n",
    "        <ul>\n",
    "            <li>\"overwrite\" : Set whether to overwrite if a dataset with the same name exists. If True, the old dataset is replaced with the new dataset (True|False, DEFAULT : False) </li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63661751-7e32-48f7-84fa-1dd205cc5d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "COPY mnist_train \n",
    "OPTIONS (overwrite=True)\n",
    "FROM \"thanosql-dataset/mnist_data/mnist_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65244d4-97bc-4464-aa8c-2d12a1f59435",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "COPY mnist_test \n",
    "OPTIONS (overwrite=True)\n",
    "FROM \"thanosql-dataset/mnist_data/mnist_test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6845948",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>Use the \"<strong>COPY</strong>\" query syntax to specify the dataset name to store in the DB. </li>\n",
    "        <li>\"<strong>OPTIONS</strong>\" Specifies the options to use for <strong>COPY</strong> query syntax.\n",
    "        <ul>\n",
    "            <li>\"overwrite\" : Set whether or not a dataset with the same name can be overwritten if it exists on the DB. If True, the existing dataset is changed to the new dataset (True|False, DEFAULT: False) </li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542deaf1-606f-49ea-9b6d-5721050ff2bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## __1. Check Dataset__\n",
    "\n",
    "To create a handwriting classification model, use the <mark style=\"background-color:#FFEC92\">mnist_train</mark> table stored in ThanoSQL [DB](https://en.wikipedia.org/wiki/Database). The <mark style=\"background-color:#FFEC92\">mnist_train</mark> table contains the path, file name, and label information that contains the <mark style=\"background-color:#FFD79C\">MNIST</mark> image files. Run the query statement below and check the contents of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242430e8-09f5-4f2c-9133-21015fc0acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "SELECT * \n",
    "FROM mnist_train \n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648a0843",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Understanding the Data Table</h4>\n",
    "    <p>The <mark style=\"background-color:#FFEC92\">mnist_train</mark> table contains the following information: The \"6782.jpg\" image file is a handwritten image with the number 5.</p>\n",
    "    <ul>\n",
    "        <li><mark style=\"background-color:#D7D0FF\">image_path</mark>: image path</li>\n",
    "        <li><mark style=\"background-color:#D7D0FF\">filename</mark>: file name</li>\n",
    "        <li><mark style=\"background-color:#D7D0FF\">label</mark>: image label</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f3acf-f218-4d51-b671-7651632290ec",
   "metadata": {},
   "source": [
    "## __2. Creating an Image Numerical Model__\n",
    "\n",
    "Create an image quantification model using the <mark style=\"background-color:#FFEC92\">mnist_train</mark> table from the previous step. Execute the query syntax below to create a model named <mark style=\"background-color:#E9D7FD\">my_image_search_model</mark>.  \n",
    "(Estimated time required for query execution: 1 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3630f8f7-8229-49f5-ae32-51011e1e37c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "BUILD MODEL my_image_search_model\n",
    "USING SimCLR\n",
    "OPTIONS (\n",
    "    image_col=\"image_path\",\n",
    "    max_epochs=1,\n",
    "    overwrite=True\n",
    "    )\n",
    "AS \n",
    "SELECT * \n",
    "FROM mnist_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e173c0d",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>Create and train a model called <mark style=\"background-color:#E9D7FD\">mnist_model</mark> using the \"<strong>BUILD MODEL</strong>\" query syntax.</li>\n",
    "        <li>The \"<strong>USING</strong>\" query syntax specifies that the <mark style=\"background-color:#E9D7FD\">SimCLR</mark> model should be used as the base model.</li>\n",
    "        <li>\"<strong>OPTIONS</strong>\" Specify the options to use to create the model through the query syntax.\n",
    "        <ul>\n",
    "            <li>\"image_col\" : Column containing the path of the image in the data table (Default: \"<mark style=\"background-color:#D7D0FF\">image_path</mark>\")</li>\n",
    "            <li>\"max_epochs\" : Number of datasets learned to generate image quantization models</li>\n",
    "            <li>\"overwrite\" : Set whether or not a model with the same name exists. If true, the existing model is changed to a new model (True|False, DEFAULT: False) </li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4b8b03",
   "metadata": {},
   "source": [
    "Run the following \"__CONVERT USING__\" query syntax to digitize the images `mnist_test`. The quantized results are stored in a column named <mark style=\"background-color:#D7D0FF\">my_image_search_model_simclr</mark> in the table `mnist_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abffc4b-aec9-444a-9546-dce181190f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "CONVERT USING my_image_search_model\n",
    "OPTIONS (\n",
    "    table_name= \"mnist_test\",\n",
    "    image_col=\"image_path\"\n",
    "    )\n",
    "AS \n",
    "SELECT * \n",
    "FROM mnist_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb189a3",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>The \"<strong>CONVERT USING</strong>\" query syntax uses <code>my_image_search_model</code> as an algorithm for image quantification.   </li>\n",
    "        <li>The \"<strong>OPTIONS</strong>\" query syntax defines the variables required for image quantification.\n",
    "        <ul>\n",
    "            <li>\"table_name\" : Defines the table name to be stored in the ThanoSQL DB. </li>\n",
    "            <li>\"image_col\" : Column containing the path of the image in the data table (default: \"image_path\")</li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c16f866-b5b4-4540-a848-30d0cd459165",
   "metadata": {},
   "source": [
    "## __3. Search for similar images using image quantization models__\n",
    "\n",
    "This step uses the <mark style=\"background-color:#E9D7FD\">my_image_search_model</mark> image quantization model and the test table to search for images similar to the \"923.jpg\" image file (handwriting 8).\n",
    "\n",
    "<a href=\"https://docs.thanosql.ai/img/thanosql_search/search_image_by_image/simclr_img8.png\">\n",
    "    <img alt=\"IMAGE\" src=\"https://docs.thanosql.ai/img/thanosql_search/search_image_by_image/simclr_img8.png\" style=\"width:100px\">\n",
    "</a>\n",
    "\n",
    "<p style=\"text-align:center\">923.jpg Image File </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e0de08-b6a7-4087-8691-230243aab016",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "SEARCH IMAGE images='thanosql-dataset/mnist_data/test/923.jpg' \n",
    "USING my_image_search_model \n",
    "AS\n",
    "SELECT * \n",
    "FROM mnist_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9871fe36",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>\"<strong>SEARCH IMAGE [images|audio|videos]</strong>\" query syntax defines the image|audio|video file you want to search for.  <br></li>\n",
    "        <li>\"<strong>USING</strong>\" defines the model used for image quantification.<br></li>\n",
    "        <li>The \"<strong>AS</strong>\" query syntax defines the embedding table to use for searches. Use the <code>mnist_embds</code> table </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12953f08",
   "metadata": {},
   "source": [
    "Run the following query to output the \"__SEARCH__\" result using the \"__PRINT__\" query syntax in ThanoSQL to output the top four most similar. We've only done a little bit of learning, but you can see that it's outputting an image similar to 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77af4961-def3-4884-bea2-b8e917d9ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "PRINT IMAGE \n",
    "AS (\n",
    "    SELECT image_path, my_image_search_model_simclr_similarity1 \n",
    "    FROM (\n",
    "        SEARCH IMAGE images='thanosql-dataset/mnist_data/test/923.jpg' \n",
    "        USING my_image_search_model \n",
    "        AS \n",
    "        SELECT * \n",
    "        FROM mnist_test\n",
    "        )\n",
    "    ORDER BY my_image_search_model_simclr_similarity1 DESC \n",
    "    LIMIT 4\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517479e8",
   "metadata": {},
   "source": [
    "<div class=\"admonition danger\">\n",
    "    <h4 class=\"admonition-title\">Note</h4>\n",
    "    <p>The basic learning options of the image similarity search algorithm are learned to recognize the image as the same regardless of the image's left-right inversion, color change, etc. This is because a dog's picture should be recognized as a dog even if it is flipped or changed in color. If color changes are important, such as clothing images, or if vertical and horizontal twists are important, such as numbers, the options should be changed when learning. This tutorial shows the characteristics of these image similarity searches.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5389cb4a",
   "metadata": {},
   "source": [
    "## __4. In Conclusion__\n",
    "\n",
    "In this tutorial, we used the `MNIST` handwriting dataset to perform image quantification and similar image search based on quantification results. In this tutorial, we explained the operation rather than the accuracy of image similarity. Image quantification models can improve accuracy by adding precise tuning and small amounts of correct answers to each image dataset during learning. You can create your own image quantization model to add search capabilities to various types of unstructured datasets and deploy your own model using Auto-ML techniques.\n",
    "<br>\n",
    "The next step is to explore the various \"__OPTIONS__\" query syntax and learning methods of image quantification models. If you want to learn more about how to build your own accurate image conversion model, go ahead with the following tutorials.\n",
    "\n",
    "- [How to Upload to ThanoSQL DB](https://docs.thanosql.ai/en/how-to_guides/ThanoSQL_connecting/data_upload/)\n",
    "- [Creating an Intermediate Similar Image Search Model]\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "    <h4 class=\"admonition-title\">Inquiries about deploying a model for your own service</h4>\n",
    "    <p>If you have any difficulties in creating your own model using ThanoSQL or applying it to the service, please feel free to contact us belowðŸ˜Š</p>\n",
    "    <p>For inquiries about building a similar image search model: contact@smartmind.team</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
