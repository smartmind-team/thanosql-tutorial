{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cfd2a8c-fdfc-4233-abd1-ece097069522",
   "metadata": {},
   "source": [
    "# __Create an image classification model__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407db758",
   "metadata": {},
   "source": [
    "## Preface\n",
    "\n",
    "- Tutorial Difficulty: â˜…â˜†â˜†â˜†â˜†\n",
    "- 10 min read\n",
    "- Languages : [SQL](https://en.wikipedia.org/wiki/SQL) (100%)\n",
    "- File location : tutorial_en/thanosql_ml/classification/image_classification.ipynb\n",
    "- References : [(AI-Hub) Product image data](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=64), [A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125a9e8e",
   "metadata": {},
   "source": [
    "## Tutorial Introduction\n",
    "\n",
    "<div class=\"admonition note\">\n",
    "   <h4 class=\"admonition-title\">Understanding Classification Operations</h4>\n",
    "   <p>Classification task is a form of <a href=\"https://en.wikipedia.org/wiki/Machine_learning\">Machine Learning</a> used to predict the category (Category or Class) to which a target belongs. For example, a classification task includes both binary classification, which classifies male or female, and multiple classification, which predicts the species of an animal (dog, cat, rabbit, etc.).</p>\n",
    "</div>\n",
    "\n",
    "Since 2010, a contest ([ImageNet](https://en.wikipedia.org/wiki/ImageNet)) has been held to classify images using artificial intelligence models. The classification performance of the winning model at the beginning of the competition was about 72%, but the [ResNet](https://arxiv.org/abs/1512.03385) model that won in 2015 recorded about 96% of the performance, and in a specific area, the classification performance of humans was started to surpass.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "   <p>The human classification capacity of the same data is said to be about 95%.</p>\n",
    "</div>\n",
    "\n",
    "Accurate image classification requires a [data labeling](https://en.wikipedia.org/wiki/Labeled_data) operation on a large dataset, but using the weights of the pre-trained AI model Recalibration for small, labeled datasets is widely used. As a result, it enables training of deep learning models even with a relatively small number of data.\n",
    "\n",
    "ThanoSQL provides a variety of pre-trained AI models, and provides a way to create models through simple query syntax. Through this, users can extract potential insights from images that are difficult to quantify features from properly trained image classification models and utilize them for various services.\n",
    "\n",
    "__The following is an example and usage of the ThanoSQL image classification model.__\n",
    "\n",
    "- ThanoSQL image classification model reduces the iteration of the process of finding suitable categories for product registration in online product sales services. You can categorize product photos with a simple query syntax. Users can save time spent on traditional image classification by only correcting some misclassified data.\n",
    "\n",
    "- If you are renting or selling art works, you can roughly classify works that are difficult to classify due to vague criteria such as the feeling, technique, and suitable location of each work using the image classification model.\n",
    "\n",
    "- It can detect and classify defective products such as scratches and damage that were visually checked in manufacturing plants. Signal information such as laser spectrum can also be applied to the image classification model through processing such as visualization transformation.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "   <p>By storing and utilizing the behavioral histories of people who like art (purchase or rental histories, preferences, etc.) In other words, you can create a model that predicts preferences in age (20s, 30s, 40s, etc.), gender (male, female), and exhibition location (home, cafe, company, etc.) using only the image of a work of art.</p>\n",
    "</div>\n",
    "\n",
    "<div class=\"admonition note\">\n",
    "   <h4 class=\"admonition-title\">In this tutorial</h4>\n",
    "   <p>ðŸ‘‰ Build a model that classifies more than 10,000 products using the <code>Product Image</code> dataset from <a href=\"https://aihub.or.kr/\">AI-Hub</a>, a leading AI open data sharing platform. The built model can be used as a detection and identification solution in smart logistics warehouses and unmanned stores. Datasets typically consist of over 10,000 commodity datasets of images and label (correct) pairs used to learn image classification techniques, and contain a total of 1,440,000 images. In this tutorial, you will only use 1,800 sheets of training data and 200 sheets of test data to learn how to use ThanoSQL and to check results quickly. <br></p>\n",
    "</div>\n",
    "\n",
    "<a href=\"https://docs.thanosql.ai/img/thanosql_ml/classification/image_classification/image_classification_data_intro.png\">\n",
    "   <img alt=\"Product Image Example\" src=\"https://docs.thanosql.ai/img/thanosql_ml/classification/image_classification/image_classification_data_intro.png\">\n",
    "</a>\n",
    "\n",
    "<div class=\"admonition warning\">\n",
    "   <h4 class=\"admonition-title\">Tutorial Precautions</h4>\n",
    "   <ul>\n",
    "      <li>The image classification model can be used to predict one target value (Target, Category/Label) from one image.</li>\n",
    "      <li>A column indicating the path of the image and a column indicating the target value of the image must exist.</li>\n",
    "      <li>The base model of the corresponding image classification model (<code>CONVNEXT</code>) uses GPU. Depending on the size of the model used and the batch size, you may run out of GPU memory. In this case, try using a smaller model or reduce the batch size.</li>\n",
    "   </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fe39bb-e2cb-497f-bff9-a51fbc633c36",
   "metadata": {},
   "source": [
    "## __0. Prepare Dataset and Model__\n",
    "\n",
    "To use the query syntax of ThanoSQL, you must create an API token and run the query below, as mentioned in the [ThanoSQL Workspace](https://docs.thanosql.ai/en/getting_started/how_to_use_ThanoSQL/#5-thanosql-workspace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b1d06-b29f-4ade-91e2-7e4c6c33f8a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext thanosql\n",
    "%thanosql API_TOKEN=<Issued_API_TOKEN>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073a6182",
   "metadata": {},
   "source": [
    "### __Prepare Dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ef9121",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "GET THANOSQL DATASET product_image_data\n",
    "OPTIONS (overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec2d024",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>\"<strong>GET THANOSQL DATASET</strong>\" Use the query syntax to save the desired dataset to the workspace. </li>\n",
    "        <li>\"<strong>OPTIONS</strong>\" Specifies the option to use for <strong>GET THANOSQL DATASET</strong> via query syntax.\n",
    "        <ul>\n",
    "            <li>\"overwrite\" : Set whether to overwrite if a dataset with the same name exists. If True, the old dataset is replaced with the new dataset (True|False, DEFAULT : False) </li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e596460-cfe4-4c42-9aeb-71ca8ed9b4d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "COPY product_image_train\n",
    "OPTIONS (overwrite=True) \n",
    "FROM \"thanosql-dataset/product_image_data/product_image_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b62469f-2a6e-443b-b317-115805e8925e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "COPY product_image_test\n",
    "OPTIONS (overwrite=True) \n",
    "FROM \"thanosql-dataset/product_image_data/product_image_test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984aefd3",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>\"<strong>COPY</strong>\" Use the query syntax to specify the name of the dataset to be saved in the DB. </li>\n",
    "        <li>Specifies the options to use for <strong>COPY</strong> via the query syntax \"<strong>OPTIONS</strong>\" .\n",
    "        <ul>\n",
    "            <li>\"overwrite\" : Set whether overwrite is possible if a dataset with the same name exists on the DB. If True, the old dataset is replaced with the new dataset (True|False, DEFAULT : False) </li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f797e8",
   "metadata": {},
   "source": [
    "### __Prepare the Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331680b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "GET THANOSQL MODEL tutorial_product_classifier\n",
    "OPTIONS (overwrite=True)\n",
    "AS tutorial_product_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38bd64f",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details </h4>\n",
    "    <ul>\n",
    "        <li>\"<strong>GET THANOSQL MODEL</strong>\" Use the query syntax to store the desired model in the workspace and DB. </li>\n",
    "        <li>\"<strong>OPTIONS</strong>\" Use the query syntax to specify the options to use for <strong>GET THANOSQL MODEL</strong>.\n",
    "        <ul>\n",
    "            <li>\"overwrite\" : Set whether datasets with the same name can be overwritten if they exist. If True, the existing dataset is changed to a new dataset (True|False, DEFAULT: False) </li>\n",
    "        </ul>\n",
    "        </li>\n",
    "        <li>Use the query syntax \"<strong>AS</strong>\" to name the model. If you are not using the AS syntax, accept the name of <code>THANOSQL MODEL</code>.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e557a156-1075-41df-b19f-ff0812a14b4c",
   "metadata": {},
   "source": [
    "## __1. Check Dataset__\n",
    "\n",
    "For this tutorial, we use the <mark style=\"background-color:#FFEC92 \">product_image_train</mark> table stored in ThanoSQL DB. Execute the query statement below to check the table contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d801df-54d2-4809-bbed-69b2818e9cec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "SELECT *\n",
    "FROM product_image_train\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e90b90",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "   <h4 class=\"admonition-title\">Understanding Data</h4>\n",
    "   <ul>\n",
    "      <li><mark style=\"background-color:#D7D0FF \">image_path</mark>: Location information of each image's file</li>\n",
    "      <li><mark style=\"background-color:#D7D0FF \">div_l</mark> : Large classification of Products</li>\n",
    "      <li><mark style=\"background-color:#D7D0FF \">div_m</mark> : middle classification of Products</li>\n",
    "      <li><mark style=\"background-color:#D7D0FF \">div_s</mark> : subclassification of Products</li>\n",
    "      <li><mark style=\"background-color:#D7D0FF \">div_n</mark> : detailed classification of Products</li>\n",
    "      <li><mark style=\"background-color:#D7D0FF \">comp_nm</mark> : Manufacturer</li>\n",
    "      <li><mark style=\"background-color:#D7D0FF \">img_prod_nm</mark> : Product name (image)</li>\n",
    "      <li><mark style=\"background-color:#D7D0FF \">multi</mark> : Whether it is a multiple product image</li>\n",
    "   </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28b5a16-ed9c-4194-9455-1751e0e3d7da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "PRINT IMAGE\n",
    "AS\n",
    "SELECT image_path\n",
    "FROM product_image_train\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b4137e-75ad-4bea-bda0-0c7fcdb3b72b",
   "metadata": {},
   "source": [
    "## __2. Predicting Product Image Classification Results Using Pre-trained Models__\n",
    "\n",
    "By executing the following query statement, you can quickly predict the results using the <mark style=\"background-color:#E9D7FD \">tutorial_product_classifier</mark> model, a pre-trained product image classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c94b69-7a76-4ecb-b122-5698786dd206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "PREDICT USING tutorial_product_classifier\n",
    "AS\n",
    "SELECT *\n",
    "FROM product_image_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcbcf7c-d66d-41e4-a54a-172f70940830",
   "metadata": {},
   "source": [
    "## __3. Create an image classification model__\n",
    "\n",
    "Create an image classification model using the <mark style=\"background-color:#FFEC92 \">product_image_train</mark> dataset from the previous step. Execute the query syntax below to create a model named <mark style=\"background-color:#E9D7FD \">my_product_classifier</mark>.  \n",
    "(Estimated duration of query execution: 5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb0317-476e-409f-baa3-dc562d924e99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "BUILD MODEL my_product_classifier\n",
    "USING ConvNeXt_Tiny\n",
    "OPTIONS (\n",
    "  image_col='image_path',\n",
    "  label_col='div_l',\n",
    "  epochs=1,\n",
    "  overwrite=True\n",
    "  )\n",
    "AS\n",
    "SELECT *\n",
    "FROM product_image_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47327fed",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>\"<strong>BUILD MODEL</strong>\" Use the query syntax to create and train the <mark style=\"background-color:#E9D7FD\">my_product_classifier</mark> model.</li>\n",
    "        <li>\"<strong>USING</strong>\" The query syntax specifies the use of <code>ConvNeXt_Tiny</code> as the base model.</li>\n",
    "        <li>\"<strong>OPTIONS</strong>\" Specifies the options used to create the model through the query syntax.\n",
    "        <ul>\n",
    "            <li>\"image_col\" : Name of column containing image path</li>\n",
    "            <li>\"label_col\" : The name of the column containing information about the target value</li>\n",
    "            <li>\"epochs : Number of times to learn all learning datasets</li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "    <p>Here, we set \"epochs\" to 1 to learn quickly. In general, larger numbers take more computation time, but predictive performance increases as training progresses.</p>\n",
    "</div>\n",
    "\n",
    "<div class=\"admonition note\">\n",
    "    <p>When <strong>overwrite is True </strong>, the user can create a data table with the same name as the previously created data table.<br>\n",
    "    On the other hand, when <strong>overwrite is False</strong>, the user cannot create a data table with the same name as the previously created data table.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6402263-ff45-45e8-b221-27c1ff97c556",
   "metadata": {},
   "source": [
    "## __4. Predict product image classification results using the generated model__\n",
    "\n",
    "Using the product image classification model created in the previous step (<mark style=\"background-color:#E9D7FD \">my_product_classifier</mark>), try to predict the target value of a specific image (data table not used for training, <mark style=\"background-color:#FFEC92\">product_image_test</mark>). After executing the query below, the prediction result is stored and returned in the <mark style=\"background-color:#D7D0FF\">predicted</mark> column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530b828d-962c-4115-a417-59ca2c621e98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "PREDICT USING my_product_classifier\n",
    "OPTIONS (\n",
    "    image_col='image_path'\n",
    "    )\n",
    "AS\n",
    "SELECT *\n",
    "FROM product_image_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d903a",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query details</h4>\n",
    "    <ul>\n",
    "        <li>Use the <mark style=\"background-color:#E9D7FD\">my_product_classifier</mark> model created in the previous step with the query syntax \"<strong>PREDICT USING</strong>\".</li>\n",
    "        <li>Specify the options to use for prediction via the \"<strong>OPTIONS</strong>\" query syntax.\n",
    "        <ul>\n",
    "            <li>\"image_col\" : The name of the column in which the path of the image to be used for prediction is recorded</li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5389cb4a",
   "metadata": {},
   "source": [
    "## __5. In Conclusion__\n",
    "\n",
    "In this tutorial, we created an image classification model using the <mark style=\"background-color:#FFD79C\">product image</mark> dataset. As this is a beginner-level tutorial, we have focused on operation rather than explaining the process to improve accuracy. The image classification model can improve its accuracy through fine tuning for each platform or service, and most satisfactory results can be obtained even with a small amount of data labeling. It is also possible to learn a base model using your own data, or to digitize and transform your data using a self-supervised model, and then distribute it using an automated machine learning (Auto-ML) technique. Create your own model and provide competitive services by combining various unstructured data (audio, video, text, etc.) and numeric data.\n",
    "\n",
    "The next step, the [Creating an Intermediate Image Classification Model] tutorial, takes an in-depth look at image classification models. If you want to learn more about how to build your own image classification model for your service, please proceed to the following tutorials.\n",
    "\n",
    "- [How to Upload to ThanoSQL DB](https://docs.thanosql.ai/en/how-to_guides/ThanoSQL_connecting/data_upload/)\n",
    "- [Creating an Intermediate Image Classification Model]\n",
    "- [Image conversion and creating My model using Auto-ML]\n",
    "- [Deploy My Image Classification model](https://docs.thanosql.ai/en/how-to_guides/ThanoSQL_connecting/thanosql_api/rest_api_thanosql_query/)\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "    <h4 class=\"admonition-title\">Inquiries about deploying a model for your own service</h4>\n",
    "    <p>If you have any difficulties in creating your own model using ThanoSQL or applying it to the service, please feel free to contact us belowðŸ˜Š</p>\n",
    "    <p>For inquiries about building an image classification model: contact@smartmind.team</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc-autonumbering": false,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
