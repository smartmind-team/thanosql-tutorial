{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cfd2a8c-fdfc-4233-abd1-ece097069522",
   "metadata": {},
   "source": [
    "# __Create a speech recognition model to dictate an audio file__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6520d41e",
   "metadata": {},
   "source": [
    "## Preface\n",
    "\n",
    "- Tutorial Difficulty : ★☆☆☆☆\n",
    "- 10 min read\n",
    "- Languages : [SQL](https://en.wikipedia.org/wiki/SQL) (100%)\n",
    "- File location : tutorial_en/thanosql_ml/audio_recognition/speech_recognition.ipynb\n",
    "- References : [LibriSpeech DataSet](http://www.openslr.org/12), [wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations](https://arxiv.org/abs/2006.11477)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f3d517",
   "metadata": {},
   "source": [
    "## Tutorial Introduction\n",
    "\n",
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Understanding Speech Recognition</h4>\n",
    "    <p>Speech recognition technology, also called computer speech recognition or speech-to-text, allows programs to process human speech into text format. Recently, it has been used in a wide range of fields ranging from automobiles, medical fields, to everyday life involving artificial intelligence speakers or smartphones. Recent <a href=\"https://en.wikipedia.org/wiki/Machine_learning\">Machine Learning</a> Speech recognition technology utilizes algorithms that understands and processes speech by integrating grammar, syntax, structure, and composition of audio and speech signals.</p>\n",
    "</div>\n",
    "\n",
    "<div class=\"admonition warning\">\n",
    "    <p>Speech Recognition should not be confused with Voice Recognition, which focuses only on identifying the individual users' voices.</p>\n",
    "</div>\n",
    "\n",
    "Today, speech recognition technology is being applied in various industries. Advances in speech recognition technology have been expanding into automatic interpretation for simple travel to high-level business meetings. In addition, it has delved into fields such as speech synthesis technology, which acts as a virtual guide, mimicking the voice of a specific celebrity, and converting a predetermined fingerprint into a voice.\n",
    "\n",
    "__The following are use case examples of ThanoSQL's speech recognition model.__\n",
    "\n",
    "- Voice recognition technology converts phone consultation data into text to enable customer sentiment analysis and consultation trend analysis. Using voice recognition technology, counselors can improve customer service by quickly receiving relevant information that answers customer inquiries or referencing similar cases in the past.\n",
    "In addition, after consultation, the customer satisfaction trend can be viewed by indirect measurement of customer satisfaction through sentiment analysis.\n",
    "\n",
    "- Using voice recognition technology, you can write notes faster than when written with a keyboard, and can instantly search for specific keywords even in long voice files.\n",
    "\n",
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">In this tutorial</h4>\n",
    "    <p>👉 Librispeech [Panayotov et al. 2015] is the result of <a href=\"https://librivox.org/\">LibriVox project</a>, a user-participating audiobook project, which is one of the most used large-scale English speech data in speech recognition research. It was created by processing approximately 1,000 hours of recorded audiobook data sampled at 16 kHz. The target table for the tutorial consists of the pre-uploaded audio file paths and scripts. This tutorial aims to convert audio files to text.</p>\n",
    "</div>\n",
    "\n",
    "<div class=\"admonition warning\">\n",
    "    <h4 class=\"admonition-title\">Tutorial Notes</h4>\n",
    "    <ul>\n",
    "        <li>ThanoSQL currently only supports the following audio file formats: '.wav', '.flac'.</li>\n",
    "        <li>Both a column indicating the audio file path and a column indicating the text corresponding to the target value must exist in the table.</li>\n",
    "        <li>The base model of the speech recognition model (<code>Wav2Vec2En</code>) utilizes GPU. Depending on the size of the model and the batch size, you may run out of GPU memory. In this case, try using a smaller model or reducing the batch size.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5a038e-2951-433a-b5b2-2cc0cf439d2e",
   "metadata": {},
   "source": [
    "## __0. Prepare Dataset and Model__\n",
    "\n",
    "To run ThanoSQL queries, you must create an API token and run the code below, as mentioned in the [ThanoSQL Workspace](https://docs.thanosql.ai/en/getting_started/how_to_use_ThanoSQL/#5-thanosql-workspace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb93ef5-7309-4842-b616-f8269965db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext thanosql\n",
    "%thanosql API_TOKEN=<Issued_API_TOKEN>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073a6182",
   "metadata": {},
   "source": [
    "### __Prepare Dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75c05e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "GET THANOSQL DATASET librispeech_data\n",
    "OPTIONS (overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec2d024",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>\"<strong>GET THANOSQL DATASET</strong>\" Use this query statement to save the desired dataset to your workspace environment. </li>\n",
    "        <li>\"<strong>OPTIONS</strong>\" Use this statement to specify the option to use for the <strong>GET THANOSQL DATASET</strong> query statement.\n",
    "        <ul>\n",
    "            <li>\"overwrite\" : Overwrite if a dataset with the same name exists. If set as True, the existing dataset is replaced with the new dataset (True|False, DEFAULT : False) </li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784d86c0-984b-4df7-a46c-b8c2294e4e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "COPY librispeech_train \n",
    "OPTIONS (overwrite=True)\n",
    "FROM \"thanosql-dataset/librispeech_data/librispeech_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe4e8d3-bbd6-4fcb-92f2-0f6263612af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "COPY librispeech_test \n",
    "OPTIONS (overwrite=True)\n",
    "FROM \"thanosql-dataset/librispeech_data/librispeech_test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984aefd3",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>Use the \"<strong>COPY</strong>\" clause to specify the dataset to be copied into the DB. </li>\n",
    "        <li>\"<strong>OPTIONS</strong>\" specifies the options to use for <strong>COPY</strong> clause.\n",
    "        <ul>\n",
    "            <li>\"overwrite\" : Overwrite if a dataset with the same name exists in the DB. If True, the existing dataset is overwritten with the new dataset. (True|False, DEFAULT : False) </li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f797e8",
   "metadata": {},
   "source": [
    "### __Prepare the Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf80d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "GET THANOSQL MODEL tutorial_audio_recognition\n",
    "OPTIONS (overwrite=True)\n",
    "AS tutorial_audio_recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38bd64f",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details </h4>\n",
    "    <ul>\n",
    "        <li>\"<strong>GET THANOSQL MODEL</strong>\" Use the query to save the desired model into your workspace environment. </li>\n",
    "        <li>\"<strong>OPTIONS</strong>\" Use this clause to specify the options to use for the <strong>GET THANOSQL MODEL</strong> statement.\n",
    "        <ul>\n",
    "            <li>\"overwrite\" : Overwrite if a dataset with the same name exists in the DB. If True, the existing dataset is overwritten with the new dataset. (True|False, DEFAULT : False) </li>\n",
    "        </ul>\n",
    "        </li>\n",
    "        <li>Use the \"<strong>AS</strong>\" clause to name the model. If you are not using the AS syntax, the default name of the <code>THANOSQL MODEL</code> is used.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e557a156-1075-41df-b19f-ff0812a14b4c",
   "metadata": {},
   "source": [
    "## __1. Check Dataset__\n",
    "\n",
    "For this tutorial, we use the <mark style=\"background-color:#FFEC92 \">librispeech_train</mark> table stored in ThanoSQL DB. Execute the query statement below to check the contents of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d801df-54d2-4809-bbed-69b2818e9cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "SELECT *\n",
    "FROM librispeech_train\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff864330",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Understanding Data</h4>\n",
    "    <ul>\n",
    "        <li><mark style=\"background-color:#D7D0FF \">audio_path</mark>: The audio file's path</li>\n",
    "        <li><mark style=\"background-color:#D7D0FF \">text</mark>: Target value of the corresponding audio (target, script)</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d7b7cc-e411-4e39-b443-1aa287a0adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "PRINT AUDIO \n",
    "AS\n",
    "SELECT audio_path\n",
    "FROM librispeech_train\n",
    "LIMIT 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3251b51-e9d8-4c5c-9882-46ca1c5d58bd",
   "metadata": {},
   "source": [
    "## __2. Predict Speech Recognition Results Using Pretrained Models__\n",
    "\n",
    "By using the pre-trained speech recognition model, <mark style=\"background-color:#E9D7FD \">tutorial_audio_recognition</mark>, and by running the following query syntax, predict the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef603c7d-ac80-4918-bb9d-d4abe3e07d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "PREDICT USING tutorial_audio_recognition\n",
    "OPTIONS (\n",
    "    audio_col='audio_path',\n",
    "    batch_size=8\n",
    "    )\n",
    "AS \n",
    "SELECT * \n",
    "FROM librispeech_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b4137e-75ad-4bea-bda0-0c7fcdb3b72b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## __3. Creating a Speech Recognition Model__\n",
    "\n",
    "Create a speech recognition model using the <mark style=\"background-color:#FFEC92 \">librispeech_train</mark> dataset from the previous step. Execute the query below to create a model named <mark style=\"background-color:#E9D7FD \">my_speech_recognition_model</mark>.  \n",
    "(Estimated time required for query execution: 1 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb0317-476e-409f-baa3-dc562d924e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "BUILD MODEL my_speech_recognition_model\n",
    "USING Wav2Vec2En\n",
    "OPTIONS (\n",
    "    audio_col='audio_path',  \n",
    "    text_col='text',  \n",
    "    epochs=1,  \n",
    "    batch_size=4,\n",
    "    overwrite= True  \n",
    "    )\n",
    "AS\n",
    "SELECT *\n",
    "FROM librispeech_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4f0cfa",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>Create and train the model <mark style=\"background-color:#E9D7FD \">my_speech_recognition_model</mark> using the \"<strong>BUILD MODEL</strong>\" statement.</li>\n",
    "        <li>Specify <code>Wav2Vec2En</code> as the base model with the \"<strong>USING</strong>\" clause.</li>\n",
    "        <li>The \"<strong>OPTIONS</strong>\" clause specifies the options to use for model creation.\n",
    "        <ul>\n",
    "            <li>\"audio_col\" : The name of the column containing the audio path to be used for training.</li>\n",
    "            <li>\"text_col\" : The name of the column containing the audio script information.</li>\n",
    "            <li>\"epochs\" : Number of times to train the training dataset.</li>\n",
    "            <li>\"batch_size\" : The size of the dataset read in a single training. </li>\n",
    "            <li>\"overwrite\" : Overwrite if a model with the same name exists. If True, the existing model is overwritten with the new model. (True|False, DEFAULT : False)</li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "    <p>In this example, we set “epochs” to 1 to train the model quickly. In general, larger number of “epochs” increases performance of the inference at the cost of the computation time.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6402263-ff45-45e8-b221-27c1ff97c556",
   "metadata": {},
   "source": [
    "## __4. Predict Speech Recognition Results Using the Model You Created__\n",
    "\n",
    "Using the speech recognition model created in the previous step, predict the target value (script) of a specific speech (a table not used for training, <mark style=\"background-color:#FFEC92 \">librispeech_test</mark>). After executing the query below, the prediction result is stored and returned in the <mark style=\"background-color:#D7D0FF\">predicted</mark> column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530b828d-962c-4115-a417-59ca2c621e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thanosql\n",
    "PREDICT USING my_speech_recognition_model\n",
    "OPTIONS (\n",
    "    audio_col='audio_path'\n",
    "    )\n",
    "AS\n",
    "SELECT *\n",
    "FROM librispeech_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7d9847",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>Use the <mark style=\"background-color:#E9D7FD \">my_speech_recognition_model</mark> model created in the previous step for prediction using the \"<strong>PREDICT USING</strong>\" statement.</li>\n",
    "        <li>The \"<strong>OPTIONS</strong>\" clause specifies the options to use for prediction.\n",
    "        <ul>\n",
    "            <li>\"audio_col\" : The name of the column containing the audio path to use for prediction.</li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5389cb4a",
   "metadata": {},
   "source": [
    "## __5. In Conclusion__\n",
    "\n",
    "In this tutorial, we created a speech recognition model using the <mark style=\"background-color:#FFD79C\">LibriSpeech</mark> dataset. As this is a beginner-level tutorial, we focused on the process rather than accuracy. Speech recognition models can improve their accuracy through fine tuning that is suitable for the user's needs. Try using your own data to train the base model and improving its performance. By combining various unstructured data (image, video, text, etc.) and numeric data, you can create your own model and create competitive services.\n",
    "\n",
    "The next tutorial, [Creating an Intermediate Speech Recognition Model], takes a deeper dive into the speech recognition model. If you want to learn more about building your own speech recognition model for your service, try the following tutorials.\n",
    "\n",
    "- [How to Upload to ThanoSQL DB](https://docs.thanosql.ai/en/how-to_guides/ThanoSQL_connecting/data_upload/)\n",
    "- [Creating an Intermediate speech recognition model]\n",
    "- [Deploying My Speech Recognition Models](https://docs.thanosql.ai/en/how-to_guides/ThanoSQL_connecting/thanosql_api/rest_api_thanosql_query/)\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "    <h4 class=\"admonition-title\">Inquiries about deploying a model for your own service</h4>\n",
    "    <p>If you have any difficulties in creating your own model using ThanoSQL or applying it to your service, please feel free to contact us below😊</p>\n",
    "    <p>For inquiries regarding building a speech recognition model: contact@smartmind.team</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc-autonumbering": false,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
