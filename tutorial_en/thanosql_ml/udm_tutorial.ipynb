{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Using the Custom Model in ThanoSQL__ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tutorial Difficulty: â˜…â˜…â˜†â˜†â˜†\n",
    "- 10 min read\n",
    "- Languages: [SQL](https://en.wikipedia.org/wiki/SQL) (50%), [Python](https://en.wikipedia.org/wiki/Python_programming_language) (50%)\n",
    "- File location: tutorial_en/thanosql_ml/udm_tutorial.ipynb\n",
    "- References: [Beans Dataset](https://github.com/AI-Lab-Makerere/ibean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Introduction\n",
    "\n",
    "<div class=\"admonition warning\">\n",
    "    <p>The corresponding feature works seamlessly in paid versions.</p>\n",
    "</div>\n",
    "\n",
    "ThanoSQL provides a feature to upload models you have created to the ThanoSQL workspace and database and use them for prediction.\n",
    " \n",
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">In This Tutorial</h4>\n",
    "    <p>ðŸ‘‰ This tutorial uses the Beans dataset. This dataset is of leaf images taken in the field in different districts in Uganda by the Makerere AI lab in collaboration with the National Crops Resources Research Institute(NaCRRI), the national body in charge of research in agriculture in Uganda.</p>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __#. Prepare the Model and Dataset Using Python__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Prepare Dataset__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and Unzip Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T08:58:09.607167Z",
     "iopub.status.busy": "2022-11-30T08:58:09.606816Z",
     "iopub.status.idle": "2022-11-30T08:58:15.156185Z",
     "shell.execute_reply": "2022-11-30T08:58:15.155021Z",
     "shell.execute_reply.started": "2022-11-30T08:58:09.607097Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import unpack_archive\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "url = \"https://storage.googleapis.com/ibeans\"\n",
    "\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    urlretrieve(f\"{url}/{split}.zip\", f\"{split}.zip\")\n",
    "    unpack_archive(f\"{split}.zip\", \".\")\n",
    "    os.remove(f\"{split}.zip\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Training Dataset \n",
    "The following code block has been referenced from this [link](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html) and has been modified for this tutorial's needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "data_transforms = {\n",
    "    \"train\": T.Compose(\n",
    "        [\n",
    "            T.RandomResizedCrop(224),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "    \"validation\": T.Compose(\n",
    "        [\n",
    "            T.Resize(224),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    split: ImageFolder(split, data_transforms[split])\n",
    "    for split in [\"train\", \"validation\"]\n",
    "}\n",
    "dataloaders = {\n",
    "    split: DataLoader(image_datasets[split], batch_size=8, shuffle=split == \"train\")\n",
    "    for split in [\"train\", \"validation\"]\n",
    "}\n",
    "dataset_sizes = {split: len(image_datasets[split]) for split in [\"train\", \"validation\"]}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Prepare the Model__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Model Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T08:58:18.392232Z",
     "iopub.status.busy": "2022-11-30T08:58:18.391026Z",
     "iopub.status.idle": "2022-11-30T08:58:18.406108Z",
     "shell.execute_reply": "2022-11-30T08:58:18.405396Z",
     "shell.execute_reply.started": "2022-11-30T08:58:18.392184Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs=3):\n",
    "    start_time = time.time()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Every epoch goes through a training and validation phase\n",
    "        for phase in [\"train\", \"validation\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward propagation \n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.argmax(outputs, dim=1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward propagation during training phase only \n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            # Save if the model accuracy is higher than the previous accuracy \n",
    "            if phase == \"validation\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - start_time\n",
    "    print(f\"Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "    print(f\"Best val Acc: {best_acc:4f}\")\n",
    "\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Model\n",
    "\n",
    "This tutorial uses mobilevit v2 as it has a high accuracy for a lightweight model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.hub.load(\"rwightman/pytorch-image-models\", \"mobilevitv2_050\", pretrained=True, num_classes=3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Save a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T08:58:26.796062Z",
     "iopub.status.busy": "2022-11-30T08:58:26.795515Z",
     "iopub.status.idle": "2022-11-30T08:59:33.271902Z",
     "shell.execute_reply": "2022-11-30T08:59:33.270449Z",
     "shell.execute_reply.started": "2022-11-30T08:58:26.796028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "train Loss: 0.5641 Acc: 0.8008\n",
      "validation Loss: 0.2618 Acc: 0.8947\n",
      "\n",
      "Training complete in 1m 6s\n",
      "Best val Acc: 0.894737\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(model, criterion, optimizer, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T08:59:33.274295Z",
     "iopub.status.busy": "2022-11-30T08:59:33.274062Z",
     "iopub.status.idle": "2022-11-30T08:59:33.312135Z",
     "shell.execute_reply": "2022-11-30T08:59:33.311366Z",
     "shell.execute_reply.started": "2022-11-30T08:59:33.274277Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(trained_model, \"trained_model.pth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Dataframe to Insert into ThanoSQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T08:59:33.313219Z",
     "iopub.status.busy": "2022-11-30T08:59:33.313052Z",
     "iopub.status.idle": "2022-11-30T08:59:41.606040Z",
     "shell.execute_reply": "2022-11-30T08:59:41.604933Z",
     "shell.execute_reply.started": "2022-11-30T08:59:33.313205Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "test_dataset = ImageFolder(\"test\", data_transforms[\"validation\"])\n",
    "\n",
    "data = np.stack([img.numpy() for img, _ in test_dataset])\n",
    "df = pd.DataFrame(pd.Series(data.tolist()), columns=[\"image\"])  # column name must be an \"image\"\n",
    "df.to_pickle(\"test_data.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __0. Prepare Dataset__\n",
    "\n",
    "As mentioned in the [ThanoSQL Workspace](https://docs.thanosql.ai/en/getting_started/paas/workspace/lab/), you must create an API token and run the query below to execute the query of ThanoSQL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext thanosql\n",
    "%thanosql API_TOKEN=<Issued_API_TOKEN>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Prepare Dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T08:59:41.697878Z",
     "iopub.status.busy": "2022-11-30T08:59:41.697366Z",
     "iopub.status.idle": "2022-11-30T09:00:18.028887Z",
     "shell.execute_reply": "2022-11-30T09:00:18.027913Z",
     "shell.execute_reply.started": "2022-11-30T08:59:41.697859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "%%thanosql\n",
    "COPY beans_test \n",
    "OPTIONS (if_exists='replace')\n",
    "FROM 'test_data.pkl'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>\"<strong>COPY</strong>\" specifies the name of the dataset to be saved as a database table.</li>\n",
    "        <li>\"<strong>OPTIONS</strong>\" specifies the option values to be used for the <strong>COPY</strong> clause.\n",
    "        <ul>\n",
    "           <li>\"if_exists\": determines how the function should handle the case where the table already exists, it can either raise an error, append to the existing table, or replace the existing table (str, optional, 'fail'|'replace'|'append', default: 'fail')</li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __1. Check Dataset__\n",
    "\n",
    "For this tutorial, we use the __beans_test__ table located in the ThanoSQL workspace database. Run the query below to check the contents of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T09:00:18.030281Z",
     "iopub.status.busy": "2022-11-30T09:00:18.029988Z",
     "iopub.status.idle": "2022-11-30T09:00:19.180944Z",
     "shell.execute_reply": "2022-11-30T09:00:19.179945Z",
     "shell.execute_reply.started": "2022-11-30T09:00:18.030253Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[-0.028684020042419434, -0.04580877348780632...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[-0.0629335269331932, -0.0629335269331932, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[1.9577873945236206, 1.8721636533737183, 1.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[0.21106265485286713, 0.0569397434592247, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[-1.3815395832061768, -1.432913899421692, -1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image\n",
       "0  [[[-0.028684020042419434, -0.04580877348780632...\n",
       "1  [[[-0.0629335269331932, -0.0629335269331932, -...\n",
       "2  [[[1.9577873945236206, 1.8721636533737183, 1.7...\n",
       "3  [[[0.21106265485286713, 0.0569397434592247, -0...\n",
       "4  [[[-1.3815395832061768, -1.432913899421692, -1..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%thanosql\n",
    "SELECT *\n",
    "FROM beans_test\n",
    "LIMIT 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Understanding the Data Table</h4>\n",
    "    <p>The <strong>beans_test</strong> table contains the following information.</p>\n",
    "    <ul>\n",
    "        <li>image: image saved in numpy format</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __2. Upload Custom Model__\n",
    "\n",
    "To upload a model created using Python in the previous step, run the following query and save the model as __beans_mobilevit__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T09:00:19.182083Z",
     "iopub.status.busy": "2022-11-30T09:00:19.181905Z",
     "iopub.status.idle": "2022-11-30T09:00:19.321253Z",
     "shell.execute_reply": "2022-11-30T09:00:19.320257Z",
     "shell.execute_reply.started": "2022-11-30T09:00:19.182066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "%%thanosql\n",
    "UPLOAD MODEL beans_mobilevit\n",
    "OPTIONS (\n",
    "    framework='pytorch',\n",
    "    overwrite=True\n",
    "    )\n",
    "FROM 'trained_model.pth'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>\"<strong>UPLOAD MODEL</strong>\" upload the model with a name of <strong>beans_mobilevit</strong> to the ThanoSQL workspace.</li>\n",
    "        <li>\"<strong>OPTIONS</strong>\" specifies the option values to be used for the <strong>UPLOAD MODEL</strong> clause.\n",
    "        <ul>\n",
    "            <li>\"framework\": specifies the model frameworkÂ (str, default: 'pytorch')</li>\n",
    "             <li>\"overwrite\": determines whether to overwrite a model if it already exists. If set as True, the old model is replaced with the new model (bool, optional, True|False, default: False)</li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition warning\">\n",
    "    <p>As of right now, ThanoSQL only supports Pytorch model for <strong>UPLOAD MODEL</strong> clause.</p>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __3. Predict Using a Custom Model__\n",
    "\n",
    "To predict class of the beans using a custom model, run the following query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T09:00:19.322848Z",
     "iopub.status.busy": "2022-11-30T09:00:19.322528Z",
     "iopub.status.idle": "2022-11-30T09:00:23.278080Z",
     "shell.execute_reply": "2022-11-30T09:00:23.277348Z",
     "shell.execute_reply.started": "2022-11-30T09:00:19.322819Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[-0.7650483846664429, -0.7821731567382812, -...</td>\n",
       "      <td>[-2.5088071823120117, -0.03282929211854935, 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[1.4097952842712402, 1.3926706314086914, 1.3...</td>\n",
       "      <td>[-1.7204804420471191, -1.7354539632797241, 3.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[-1.1760425567626953, -1.1931673288345337, -...</td>\n",
       "      <td>[-0.5441469550132751, 2.5831964015960693, -2.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[-1.2445416450500488, -1.278791069984436, -1...</td>\n",
       "      <td>[-1.5955406427383423, -2.174574613571167, 3.78...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[0.4165596663951874, 0.33093592524528503, 0....</td>\n",
       "      <td>[-1.5648517608642578, -1.0658249855041504, 2.6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  \\\n",
       "0  [[[-0.7650483846664429, -0.7821731567382812, -...   \n",
       "1  [[[1.4097952842712402, 1.3926706314086914, 1.3...   \n",
       "2  [[[-1.1760425567626953, -1.1931673288345337, -...   \n",
       "3  [[[-1.2445416450500488, -1.278791069984436, -1...   \n",
       "4  [[[0.4165596663951874, 0.33093592524528503, 0....   \n",
       "\n",
       "                                           predicted  \n",
       "0  [-2.5088071823120117, -0.03282929211854935, 2....  \n",
       "1  [-1.7204804420471191, -1.7354539632797241, 3.5...  \n",
       "2  [-0.5441469550132751, 2.5831964015960693, -2.0...  \n",
       "3  [-1.5955406427383423, -2.174574613571167, 3.78...  \n",
       "4  [-1.5648517608642578, -1.0658249855041504, 2.6...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%thanosql\n",
    "PREDICT USING beans_mobilevit\n",
    "OPTIONS (\n",
    "    result_col='predicted'\n",
    "    )\n",
    "AS (\n",
    "    SELECT *\n",
    "    FROM beans_test\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 5\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query details</h4>\n",
    "    <ul>\n",
    "        <li>\"<strong>PREDICT USING</strong>\" predicts the outcome using the <strong>beans_mobilevit</strong>.\n",
    "        <li>\"<strong>OPTIONS</strong>\" specifies the option values to be used for prediction.\n",
    "        <ul>\n",
    "            <li>\"result_col\": the column that contains the predicted results (str, optional, default: 'predict_result')</li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T09:00:23.279051Z",
     "iopub.status.busy": "2022-11-30T09:00:23.278898Z",
     "iopub.status.idle": "2022-11-30T09:00:23.974810Z",
     "shell.execute_reply": "2022-11-30T09:00:23.974093Z",
     "shell.execute_reply.started": "2022-11-30T09:00:23.279038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[-0.7650483846664429, -0.7821731567382812, -...</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[1.4097952842712402, 1.3926706314086914, 1.3...</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[-1.1760425567626953, -1.1931673288345337, -...</td>\n",
       "      <td>bean_rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[-1.2445416450500488, -1.278791069984436, -1...</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[0.4165596663951874, 0.33093592524528503, 0....</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  predicted\n",
       "0  [[[-0.7650483846664429, -0.7821731567382812, -...    healthy\n",
       "1  [[[1.4097952842712402, 1.3926706314086914, 1.3...    healthy\n",
       "2  [[[-1.1760425567626953, -1.1931673288345337, -...  bean_rust\n",
       "3  [[[-1.2445416450500488, -1.278791069984436, -1...    healthy\n",
       "4  [[[0.4165596663951874, 0.33093592524528503, 0....    healthy"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = _ # get the object that has been used last \n",
    "pred_df[\"predict_result\"] = pred_df[\"predict_result\"].apply(np.argmax)\n",
    "pred_df[\"predict_result\"] = pred_df[\"predict_result\"].apply(test_dataset.classes.__getitem__)\n",
    "pred_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __4. In Conclusion__\n",
    "\n",
    "In this tutorial, we uploaded a custom model to ThanoSQL and used that model for prediction of the classes of beans. You can refer back to this tutorial to upload your own custom model and use it within ThanoSQL.\n",
    "\n",
    "* [How to Upload My Data to the ThanoSQL Workspace](https://docs.thanosql.ai/en/getting_started/data_upload/)\n",
    "* [How to Create a Table Using My Data](https://docs.thanosql.ai/en/how-to_guides/ThanoSQL_query/COPY_SYNTAX/)\n",
    "* [How to Upload My Model to the ThanoSQL Workspace](https://docs.thanosql.ai/en/how-to_guides/ThanoSQL_query/UPLOAD_MODEL_SYNTAX/)\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "    <h4 class=\"admonition-title\">Inquiries About Deploying a Model for Your Own Service</h4>\n",
    "    <p>If you have any difficulties creating your own model using ThanoSQL or applying it to your service, please feel free to contact us belowðŸ˜Š</p>\n",
    "    <p>For inquiries regarding building an user defined model: <a href=\"mailto:contact@smartmind.team\">contact@smartmind.team</a></p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
