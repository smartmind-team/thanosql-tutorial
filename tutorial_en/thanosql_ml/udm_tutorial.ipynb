{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Using the Custom Model in ThanoSQL__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __0. Prepare Dataset and Model__\n",
    "\n",
    "This tutorial uses the Beans dataset. This dataset is of leaf images taken in the field in different districts in Uganda by the Makerere AI lab in collaboration with the National Crops Resources Research Institute (NaCRRI), the national body in charge of research in agriculture in Uganda.\n",
    "\n",
    "\n",
    "\n",
    "Reference: <https://github.com/AI-Lab-Makerere/ibean>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Prepare Dataset__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and Unzip Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import unpack_archive\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "url = \"https://storage.googleapis.com/ibeans\"\n",
    "\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    urlretrieve(f\"{url}/{split}.zip\", f\"{split}.zip\")\n",
    "    unpack_archive(f\"{split}.zip\", \".\")\n",
    "    os.remove(f\"{split}.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Training Dataset \n",
    "Following code block has been referenced from this [link](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html) and has been modified for this tutorial's need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "data_transforms = {\n",
    "    \"train\": T.Compose(\n",
    "        [\n",
    "            T.RandomResizedCrop(224),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "    \"validation\": T.Compose(\n",
    "        [\n",
    "            T.Resize(224),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    split: ImageFolder(split, data_transforms[split])\n",
    "    for split in [\"train\", \"validation\"]\n",
    "}\n",
    "dataloaders = {\n",
    "    split: DataLoader(image_datasets[split], batch_size=8, shuffle=split == \"train\")\n",
    "    for split in [\"train\", \"validation\"]\n",
    "}\n",
    "dataset_sizes = {split: len(image_datasets[split]) for split in [\"train\", \"validation\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Prepare the Model__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Model Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs=3):\n",
    "    start_time = time.time()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Every epoch goes through a training and validation phase\n",
    "        for phase in [\"train\", \"validation\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward propagation \n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.argmax(outputs, dim=1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward propagation during training phase only \n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            # Save if the model accuracy is higher than the previous accuracy \n",
    "            if phase == \"validation\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - start_time\n",
    "    print(f\"Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "    print(f\"Best val Acc: {best_acc:4f}\")\n",
    "\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Model\n",
    "\n",
    "This tutorial uses mobilevit v2 as it has a high accuracy for a lightweight model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load(\"rwightman/pytorch-image-models\", \"mobilevitv2_050\", pretrained=True, num_classes=3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Save a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2\n",
      "----------\n",
      "train Loss: 0.5634 Acc: 0.7921\n",
      "validation Loss: 0.2599 Acc: 0.8947\n",
      "\n",
      "Epoch 1/2\n",
      "----------\n",
      "train Loss: 0.3259 Acc: 0.8762\n",
      "validation Loss: 0.2687 Acc: 0.9173\n",
      "\n",
      "Epoch 2/2\n",
      "----------\n",
      "train Loss: 0.2883 Acc: 0.8830\n",
      "validation Loss: 0.1434 Acc: 0.9624\n",
      "\n",
      "Training complete in 1m 26s\n",
      "Best val Acc: 0.962406\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(model, criterion, optimizer, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model, \"trained_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Dataframe to Insert into the ThanoSQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "test_dataset = ImageFolder(\"test\", data_transforms[\"validation\"])\n",
    "\n",
    "data = np.stack([img.numpy() for img, _ in test_dataset])\n",
    "df = pd.DataFrame(pd.Series(data.tolist()), columns=[\"image\"])  # column name must be an \"image\"\n",
    "df.to_pickle(\"test_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the [ThanoSQL Workspace](https://docs.thanosql.ai/en/getting_started/how_to_use_ThanoSQL/#5-thanosql-workspace), you must create an API token and run the query below to execute the query of ThanoSQL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext thanosql\n",
    "%thanosql API_TOKEN=<Issued_API_TOKEN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "%%thanosql\n",
    "COPY beans_test \n",
    "OPTIONS (overwrite=True)\n",
    "FROM \"test/udm_tutorial/test_data.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>\"<strong>COPY</strong>\" specifies the name of the dataset to be saved as a database table. </li>\n",
    "        <li>\"<strong>OPTIONS</strong>\" specifies the option values to be used for the <strong>COPY</strong> clause.\n",
    "        <ul>\n",
    "           <li>\"overwrite\": determines whether to overwrite a table if it already exists. If set as True, the old table is replaced with the new table (True|False, DEFAULT: False) </li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __1.Check Dataset__\n",
    "\n",
    "To check the table's contents, run the following query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[-0.028684020042419434, -0.04580877348780632...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[-0.0629335269331932, -0.0629335269331932, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[1.9577873945236206, 1.8721636533737183, 1.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[0.21106265485286713, 0.0569397434592247, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[-1.3815395832061768, -1.432913899421692, -1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image\n",
       "0  [[[-0.028684020042419434, -0.04580877348780632...\n",
       "1  [[[-0.0629335269331932, -0.0629335269331932, -...\n",
       "2  [[[1.9577873945236206, 1.8721636533737183, 1.7...\n",
       "3  [[[0.21106265485286713, 0.0569397434592247, -0...\n",
       "4  [[[-1.3815395832061768, -1.432913899421692, -1..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%thanosql\n",
    "SELECT *\n",
    "FROM beans_test\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __2. Upload Custom Model__\n",
    "\n",
    "To upload a custom model, run the following query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "%%thanosql\n",
    "UPLOAD MODEL beans_mobilevit\n",
    "OPTIONS (\n",
    "    overwrite=True,\n",
    "    framework=\"pytorch\"\n",
    "    )\n",
    "FROM \"test/udm_tutorial/trained_model.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __3. Predict Using a Custom Model__\n",
    "\n",
    "To predict the result using a custom model, run the following query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>predict_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[-0.09718302637338638, -0.11430778354406357,...</td>\n",
       "      <td>[-1.734525203704834, -1.7788751125335693, 3.94...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[-1.3986643552780151, -1.4500386714935303, -...</td>\n",
       "      <td>[-1.6501493453979492, -1.6760544776916504, 3.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[-1.4157891273498535, -1.4842880964279175, -...</td>\n",
       "      <td>[-1.0188010931015015, 3.2187016010284424, -2.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[-1.2445416450500488, -1.158917784690857, -1...</td>\n",
       "      <td>[-1.5477955341339111, 2.5614449977874756, -1.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[-1.2445416450500488, -1.278791069984436, -1...</td>\n",
       "      <td>[-2.2948460578918457, -1.4243049621582031, 4.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  \\\n",
       "0  [[[-0.09718302637338638, -0.11430778354406357,...   \n",
       "1  [[[-1.3986643552780151, -1.4500386714935303, -...   \n",
       "2  [[[-1.4157891273498535, -1.4842880964279175, -...   \n",
       "3  [[[-1.2445416450500488, -1.158917784690857, -1...   \n",
       "4  [[[-1.2445416450500488, -1.278791069984436, -1...   \n",
       "\n",
       "                                      predict_result  \n",
       "0  [-1.734525203704834, -1.7788751125335693, 3.94...  \n",
       "1  [-1.6501493453979492, -1.6760544776916504, 3.8...  \n",
       "2  [-1.0188010931015015, 3.2187016010284424, -2.8...  \n",
       "3  [-1.5477955341339111, 2.5614449977874756, -1.3...  \n",
       "4  [-2.2948460578918457, -1.4243049621582031, 4.2...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%thanosql\n",
    "PREDICT\n",
    "USING beans_mobilevit\n",
    "AS (\n",
    "    SELECT *\n",
    "    FROM beans_test\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>predict_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[-0.09718302637338638, -0.11430778354406357,...</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[-1.3986643552780151, -1.4500386714935303, -...</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[-1.4157891273498535, -1.4842880964279175, -...</td>\n",
       "      <td>bean_rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[-1.2445416450500488, -1.158917784690857, -1...</td>\n",
       "      <td>bean_rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[-1.2445416450500488, -1.278791069984436, -1...</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image predict_result\n",
       "0  [[[-0.09718302637338638, -0.11430778354406357,...        healthy\n",
       "1  [[[-1.3986643552780151, -1.4500386714935303, -...        healthy\n",
       "2  [[[-1.4157891273498535, -1.4842880964279175, -...      bean_rust\n",
       "3  [[[-1.2445416450500488, -1.158917784690857, -1...      bean_rust\n",
       "4  [[[-1.2445416450500488, -1.278791069984436, -1...        healthy"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = _ \n",
    "pred_df[\"predict_result\"] = pred_df[\"predict_result\"].apply(np.argmax)\n",
    "pred_df[\"predict_result\"] = pred_df[\"predict_result\"].apply(test_dataset.classes.__getitem__)\n",
    "pred_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
