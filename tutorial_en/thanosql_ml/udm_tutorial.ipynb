{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Using the Custom Model in ThanoSQL__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __0. Prepare Dataset and Model__\n",
    "\n",
    "This tutorial uses the Beans dataset. This dataset is of leaf images taken in the field in different districts in Uganda by the Makerere AI lab in collaboration with the National Crops Resources Research Institute (NaCRRI), the national body in charge of research in agriculture in Uganda.\n",
    "\n",
    "\n",
    "\n",
    "Reference: <https://github.com/AI-Lab-Makerere/ibean>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Prepare Dataset__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and Unzip Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import unpack_archive\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "url = \"https://storage.googleapis.com/ibeans\"\n",
    "\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    urlretrieve(f\"{url}/{split}.zip\", f\"{split}.zip\")\n",
    "    unpack_archive(f\"{split}.zip\", \".\")\n",
    "    os.remove(f\"{split}.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (1.12.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.13.1-cp39-cp39-manylinux1_x86_64.whl (19.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m211.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from torchvision) (2.27.1)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-9.2.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m297.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from torchvision) (1.23.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision) (2021.10.8)\n",
      "Installing collected packages: pillow, torchvision\n",
      "Successfully installed pillow-9.2.0 torchvision-0.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Training Dataset \n",
    "Following code block has been referenced from this [link](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html) and has been modified for this tutorial's need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "data_transforms = {\n",
    "    \"train\": T.Compose(\n",
    "        [\n",
    "            T.RandomResizedCrop(224),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "    \"validation\": T.Compose(\n",
    "        [\n",
    "            T.Resize(224),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    split: ImageFolder(split, data_transforms[split])\n",
    "    for split in [\"train\", \"validation\"]\n",
    "}\n",
    "dataloaders = {\n",
    "    split: DataLoader(image_datasets[split], batch_size=8, shuffle=split == \"train\")\n",
    "    for split in [\"train\", \"validation\"]\n",
    "}\n",
    "dataset_sizes = {split: len(image_datasets[split]) for split in [\"train\", \"validation\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Prepare the Model__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Model Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs=3):\n",
    "    start_time = time.time()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Every epoch goes through a training and validation phase\n",
    "        for phase in [\"train\", \"validation\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward propagation \n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.argmax(outputs, dim=1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward propagation during training phase only \n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            # Save if the model accuracy is higher than the previous accuracy \n",
    "            if phase == \"validation\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - start_time\n",
    "    print(f\"Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "    print(f\"Best val Acc: {best_acc:4f}\")\n",
    "\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Model\n",
    "\n",
    "This tutorial uses mobilevit v2 as it has a high accuracy for a lightweight model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/hub.py:266: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n",
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/zipball/master\" to /home/jovyan/.cache/torch/hub/master.zip\n",
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevitv2_050-49951ee2.pth\" to /home/jovyan/.cache/torch/hub/checkpoints/mobilevitv2_050-49951ee2.pth\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"rwightman/pytorch-image-models\", \"mobilevitv2_050\", pretrained=True, num_classes=3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Save a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2\n",
      "----------\n",
      "train Loss: 0.5687 Acc: 0.7853\n",
      "validation Loss: 0.1443 Acc: 0.9624\n",
      "\n",
      "Epoch 1/2\n",
      "----------\n",
      "train Loss: 0.3428 Acc: 0.8675\n",
      "validation Loss: 0.1300 Acc: 0.9699\n",
      "\n",
      "Epoch 2/2\n",
      "----------\n",
      "train Loss: 0.2868 Acc: 0.8956\n",
      "validation Loss: 0.2953 Acc: 0.9098\n",
      "\n",
      "Training complete in 2m 54s\n",
      "Best val Acc: 0.969925\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(model, criterion, optimizer, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model, \"trained_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Dataframe to Insert into the ThanoSQL Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "test_dataset = ImageFolder(\"test\", data_transforms[\"validation\"])\n",
    "\n",
    "data = np.stack([img.numpy() for img, _ in test_dataset])\n",
    "df = pd.DataFrame(pd.Series(data.tolist()), columns=[\"image\"])  # column name must be an \"image\"\n",
    "df.to_pickle(\"test_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the [ThanoSQL Workspace](https://docs.thanosql.ai/en/getting_started/how_to_use_ThanoSQL/#5-thanosql-workspace), you must create an API token and run the query below to execute the query of ThanoSQL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext thanosql\n",
    "%thanosql API_TOKEN=<Issued_API_TOKEN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "%%thanosql\n",
    "COPY beans_test \n",
    "OPTIONS (overwrite=True)\n",
    "FROM \"test/udm_tutorial/test_data.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <h4 class=\"admonition-title\">Query Details</h4>\n",
    "    <ul>\n",
    "        <li>\"<strong>COPY</strong>\" specifies the name of the dataset to be saved as a database table. </li>\n",
    "        <li>\"<strong>OPTIONS</strong>\" specifies the option values to be used for the <strong>COPY</strong> clause.\n",
    "        <ul>\n",
    "           <li>\"overwrite\" : determines whether to overwrite a table if it already exists. If set as True, the old table is replaced with the new table (True|False, DEFAULT : False) </li>\n",
    "        </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __1.Check Dataset__\n",
    "\n",
    "To check the table's contents, run the following query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[-0.02868402, -0.045808773500000004, -0.2170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[-0.06293352690000001, -0.06293352690000001,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[1.9577873945, 1.8721636534, 1.7180408239, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[0.2110626549, 0.0569397435, -0.3026800752, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[-1.3815395832, -1.4329138994, -1.5014128685...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>[[[-0.0971830264, -0.11430778350000001, -0.114...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>[[[-0.5938008428, -1.1589177847, -1.0732940435...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>[[[-0.4396780729, -0.2170563042, -0.2513058186...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>[[[-2.0322802067, -1.9809060097, -1.9124069214...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>[[[-1.27879107, -1.2959158420999999, -1.364414...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 image\n",
       "0    [[[-0.02868402, -0.045808773500000004, -0.2170...\n",
       "1    [[[-0.06293352690000001, -0.06293352690000001,...\n",
       "2    [[[1.9577873945, 1.8721636534, 1.7180408239, 1...\n",
       "3    [[[0.2110626549, 0.0569397435, -0.3026800752, ...\n",
       "4    [[[-1.3815395832, -1.4329138994, -1.5014128685...\n",
       "..                                                 ...\n",
       "123  [[[-0.0971830264, -0.11430778350000001, -0.114...\n",
       "124  [[[-0.5938008428, -1.1589177847, -1.0732940435...\n",
       "125  [[[-0.4396780729, -0.2170563042, -0.2513058186...\n",
       "126  [[[-2.0322802067, -1.9809060097, -1.9124069214...\n",
       "127  [[[-1.27879107, -1.2959158420999999, -1.364414...\n",
       "\n",
       "[128 rows x 1 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%thanosql\n",
    "SELECT *\n",
    "FROM beans_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __2. Upload Custom Model__\n",
    "\n",
    "To upload a custom model, run the following query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "%%thanosql\n",
    "UPLOAD MODEL beans_mobilevit\n",
    "OPTIONS (overwrite=True, framework=\"pytorch\")\n",
    "FROM \"test/udm_tutorial/trained_model.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __3. Predict Using a Custom Model__\n",
    "\n",
    "To predict the result using a custom model, run the following query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[-1.9124069214000001, -1.6555356979, -1.4842...</td>\n",
       "      <td>[-1.3859444857, -0.6104061604000001, 2.0402860...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[0.3823101819, 0.7761794925000001, 1.0501755...</td>\n",
       "      <td>[1.8987154961, 1.711524725, -3.7767300606000003]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[-0.3883038163, -0.456802845, -0.5595513582,...</td>\n",
       "      <td>[-0.4351696968, 2.8146388531, -2.7762613297]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[-1.6212861538, -1.6041613817, -1.4671633244...</td>\n",
       "      <td>[-2.0298011303, -0.8211234808000001, 2.9834887...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[-0.9876701832, -0.8335474133, -0.7136741281...</td>\n",
       "      <td>[3.9639098644, -2.0307672024, -1.6559199095000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  \\\n",
       "0  [[[-1.9124069214000001, -1.6555356979, -1.4842...   \n",
       "1  [[[0.3823101819, 0.7761794925000001, 1.0501755...   \n",
       "2  [[[-0.3883038163, -0.456802845, -0.5595513582,...   \n",
       "3  [[[-1.6212861538, -1.6041613817, -1.4671633244...   \n",
       "4  [[[-0.9876701832, -0.8335474133, -0.7136741281...   \n",
       "\n",
       "                                           predicted  \n",
       "0  [-1.3859444857, -0.6104061604000001, 2.0402860...  \n",
       "1   [1.8987154961, 1.711524725, -3.7767300606000003]  \n",
       "2       [-0.4351696968, 2.8146388531, -2.7762613297]  \n",
       "3  [-2.0298011303, -0.8211234808000001, 2.9834887...  \n",
       "4  [3.9639098644, -2.0307672024, -1.6559199095000...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%thanosql\n",
    "PREDICT\n",
    "USING beans_mobilevit\n",
    "AS\n",
    "SELECT *\n",
    "FROM beans_test\n",
    "ORDER BY RANDOM()\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[-1.9124069214000001, -1.6555356979, -1.4842...</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[0.3823101819, 0.7761794925000001, 1.0501755...</td>\n",
       "      <td>angular_leaf_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[-0.3883038163, -0.456802845, -0.5595513582,...</td>\n",
       "      <td>bean_rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[-1.6212861538, -1.6041613817, -1.4671633244...</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[-0.9876701832, -0.8335474133, -0.7136741281...</td>\n",
       "      <td>angular_leaf_spot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image          predicted\n",
       "0  [[[-1.9124069214000001, -1.6555356979, -1.4842...            healthy\n",
       "1  [[[0.3823101819, 0.7761794925000001, 1.0501755...  angular_leaf_spot\n",
       "2  [[[-0.3883038163, -0.456802845, -0.5595513582,...          bean_rust\n",
       "3  [[[-1.6212861538, -1.6041613817, -1.4671633244...            healthy\n",
       "4  [[[-0.9876701832, -0.8335474133, -0.7136741281...  angular_leaf_spot"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = _ \n",
    "pred_df[\"predicted\"] = pred_df[\"predicted\"].apply(np.argmax)\n",
    "pred_df[\"predicted\"] = pred_df[\"predicted\"].apply(test_dataset.classes.__getitem__)\n",
    "pred_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
